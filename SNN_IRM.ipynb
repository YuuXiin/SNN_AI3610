{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.datasets.utils as dataset_utils\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "train1 = torch.load(r'D:\\Projects\\Brain\\ColoredMNIST\\train1.pt',weights_only=False)\n",
    "train2 = torch.load(r'D:\\Projects\\Brain\\ColoredMNIST\\train2.pt',weights_only=False)\n",
    "test = torch.load(r'D:\\Projects\\Brain\\ColoredMNIST\\test.pt',weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_load(raw_dataset):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for one_data in raw_dataset:\n",
    "        y.append(one_data[1])\n",
    "        image=one_data[0]\n",
    "        data=np.array(image)\n",
    "        data=data.transpose(2,0,1)\n",
    "        x.append(data)\n",
    "    x=torch.Tensor(np.array(x))\n",
    "    y=torch.Tensor(np.array(y))\n",
    "    ds=torch.utils.data.TensorDataset(x,y)\n",
    "    return ds\n",
    "torch_dataset_train1=dataset_load(train1)\n",
    "torch_dataset_train2=dataset_load(train2)\n",
    "torch_dataset_test=dataset_load(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def make_env(raw_dataset):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for one_data in raw_dataset:\n",
    "        y.append(one_data[1])\n",
    "        image=one_data[0]\n",
    "        data=np.array(image)\n",
    "        data=data.transpose(2,0,1)\n",
    "        x.append(data)\n",
    "    x=torch.Tensor(np.array(x))\n",
    "    y=torch.Tensor(np.array(y))\n",
    "    return {\n",
    "      'images': x,\n",
    "      'labels': y\n",
    "    }\n",
    "\n",
    "envs=[make_env(train1),make_env(train2),make_env(test)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def make_env(raw_dataset):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for one_data in raw_dataset:\n",
    "        y.append(one_data[1])\n",
    "        image=one_data[0]\n",
    "        data=np.array(image)\n",
    "        data=data.transpose(2,0,1)\n",
    "        x.append(data)\n",
    "    x=torch.Tensor(np.array(x))\n",
    "    y=torch.Tensor(np.array(y))\n",
    "    return {\n",
    "      'images': x,\n",
    "      'labels': y\n",
    "    }\n",
    "\n",
    "envs=[make_env(train1),make_env(train2),make_env(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flags:\n",
      "\tT: 1\n",
      "\tgrayscale_model: False\n",
      "\thidden_dim: 800\n",
      "\tl2_regularizer_weight: 0.00110794568\n",
      "\tlr: 0.0004898536566546834\n",
      "\tn_restarts: 1\n",
      "\tpenalty_anneal_iters: 100\n",
      "\tpenalty_weight: 5000\n",
      "\tsteps: 80\n",
      "\ttau: 2.0\n",
      "Restart 0\n",
      "step            train nll       train acc       train penalty   test acc     \n",
      "0               0.69315         0.50813         0.00000         0.50210      \n",
      "10              0.69311         0.50813         1.46139e-09     0.50210      \n",
      "20              0.69308         0.50813         4.29007e-09     0.50210      \n",
      "30              0.69306         0.50813         6.90887e-09     0.50210      \n",
      "40              0.69304         0.50813         8.74311e-09     0.50210      \n",
      "50              0.69303         0.50813         9.89245e-09     0.50210      \n",
      "60              0.69302         0.50813         1.06884e-08     0.50210      \n",
      "70              0.69302         0.50813         1.13894e-08     0.50210      \n",
      "Final train acc (mean/std across restarts so far):\n",
      "0.508125 0.0\n",
      "Final test acc (mean/std across restarts so far):\n",
      "0.5021 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define and instantiate the model\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch import nn, optim, autograd\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Colored MNIST')\n",
    "parser.add_argument('--hidden_dim', type=int, default=800)\n",
    "parser.add_argument('--l2_regularizer_weight', type=float,default=0.00110794568)\n",
    "parser.add_argument('--lr', type=float, default=0.0004898536566546834)\n",
    "parser.add_argument('--n_restarts', type=int, default=1)\n",
    "parser.add_argument('--penalty_anneal_iters', type=int, default=100)\n",
    "parser.add_argument('--penalty_weight', type=float, default=91257.18613115903)\n",
    "parser.add_argument('--steps', type=int, default=80)\n",
    "parser.add_argument('--grayscale_model', action='store_true')\n",
    "parser.add_argument('-tau', default=2.0, type=float, help='parameter tau of LIF neuron')\n",
    "parser.add_argument('-T', default=1, type=int, help='simulating time-steps')\n",
    "flags = parser.parse_known_args()[0]\n",
    "\n",
    "print('Flags:')\n",
    "for k,v in sorted(vars(flags).items()):\n",
    "  print(\"\\t{}: {}\".format(k, v))\n",
    "\n",
    "final_train_accs = []\n",
    "final_test_accs = []\n",
    "# mnist = datasets.MNIST('~/datasets/mnist', train=True, download=True)\n",
    "# mnist_train = (mnist.data[:50000], mnist.targets[:50000])\n",
    "# mnist_val = (mnist.data[50000:], mnist.targets[50000:])\n",
    "for restart in range(flags.n_restarts):\n",
    "    print(\"Restart\", restart)\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, tau):\n",
    "            super(MLP, self).__init__()\n",
    "            if flags.grayscale_model:\n",
    "                lin1 = nn.Linear(28 * 28, flags.hidden_dim)\n",
    "            else:\n",
    "                lin1 = nn.Linear(3 * 28 * 28, flags.hidden_dim)\n",
    "            lin2 = nn.Linear(flags.hidden_dim, flags.hidden_dim)\n",
    "            lin3 = nn.Linear(flags.hidden_dim, 1)\n",
    "            for lin in [lin1, lin2, lin3]:\n",
    "                nn.init.xavier_uniform_(lin.weight)\n",
    "                nn.init.zeros_(lin.bias)\n",
    "            self._main = nn.Sequential(lin1, neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()), neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()), lin3)\n",
    "        def forward(self, input):\n",
    "            if flags.grayscale_model:\n",
    "                out = input.view(input.shape[0],-1, 3, 28 * 28).sum(dim=1)\n",
    "            else:\n",
    "                out = input.view(input.shape[0], -1,3 * 28 * 28)\n",
    "            out = self._main(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    mlp=MLP(tau = flags.tau)\n",
    "\n",
    "    # Define loss function helpers\n",
    "\n",
    "    def mean_nll(logits, y):\n",
    "        return nn.functional.binary_cross_entropy_with_logits(logits, y)\n",
    "\n",
    "    def mean_accuracy(logits, y):\n",
    "        preds = (logits > 0.).float()\n",
    "        return ((preds - y).abs() < 1e-2).float().mean()\n",
    "\n",
    "    def penalty(logits, y):\n",
    "        scale = torch.tensor(1.).requires_grad_()\n",
    "        loss = mean_nll(logits * scale, y)\n",
    "        grad = autograd.grad(loss, [scale], create_graph=True)[0]\n",
    "        return torch.sum(grad**2)\n",
    "\n",
    "    # Train loop\n",
    "    def pretty_print(*values):\n",
    "        col_width = 13\n",
    "        def format_val(v):\n",
    "            if not isinstance(v, str):\n",
    "                v = np.array2string(v, precision=5, floatmode='fixed')\n",
    "            return v.ljust(col_width)\n",
    "        str_values = [format_val(v) for v in values]\n",
    "        print(\"   \".join(str_values))\n",
    "\n",
    "    optimizer = optim.Adam(mlp.parameters(), lr=flags.lr)\n",
    "    encoder = encoding.PoissonEncoder()\n",
    "\n",
    "    pretty_print('step', 'train nll', 'train acc', 'train penalty', 'test acc')\n",
    "\n",
    "    for step in range(flags.steps):\n",
    "        for env in envs:\n",
    "            logits = 0.\n",
    "            for t in range(flags.T):\n",
    "                encode_img = encoder(env['images'])\n",
    "                res = mlp(encode_img)\n",
    "                logits = logits + res\n",
    "            logits = logits / flags.T\n",
    "            logits=logits.squeeze()\n",
    "            env['nll'] = mean_nll(logits, env['labels'])\n",
    "            env['acc'] = mean_accuracy(logits, env['labels'])\n",
    "            env['penalty'] = penalty(logits, env['labels'])\n",
    "\n",
    "        train_nll = torch.stack([envs[0]['nll'], envs[1]['nll']]).mean()\n",
    "        train_acc = torch.stack([envs[0]['acc'], envs[1]['acc']]).mean()\n",
    "        train_penalty = torch.stack([envs[0]['penalty'], envs[1]['penalty']]).mean()\n",
    "\n",
    "        weight_norm = torch.tensor(0.)\n",
    "        for w in mlp.parameters():\n",
    "            weight_norm += w.norm().pow(2)\n",
    "\n",
    "        loss = train_nll.clone()\n",
    "        loss += flags.l2_regularizer_weight * weight_norm\n",
    "        penalty_weight = (flags.penalty_weight \n",
    "            if step >= flags.penalty_anneal_iters else 1.0)\n",
    "        loss += penalty_weight * train_penalty\n",
    "        if penalty_weight > 1.0:\n",
    "            # Rescale the entire loss to keep gradients in a reasonable range\n",
    "            loss /= penalty_weight\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        functional.reset_net(mlp)\n",
    "\n",
    "        test_acc = envs[2]['acc']\n",
    "        if step % 10 == 0:\n",
    "            pretty_print(\n",
    "            np.int32(step),\n",
    "            train_nll.detach().cpu().numpy(),\n",
    "            train_acc.detach().cpu().numpy(),\n",
    "            train_penalty.detach().cpu().numpy(),\n",
    "            test_acc.detach().cpu().numpy()\n",
    "            )\n",
    "\n",
    "    final_train_accs.append(train_acc.detach().cpu().numpy())\n",
    "    final_test_accs.append(test_acc.detach().cpu().numpy())\n",
    "    print('Final train acc (mean/std across restarts so far):')\n",
    "    print(np.mean(final_train_accs), np.std(final_train_accs))\n",
    "    print('Final test acc (mean/std across restarts so far):')\n",
    "    print(np.mean(final_test_accs), np.std(final_test_accs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高级部分：探索OOD算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明、分析算法的因果推理能力和收敛性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
