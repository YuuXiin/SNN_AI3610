{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerSNN(\n",
      "  (patch_embed): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(7, 7), stride=(7, 7))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=s)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (snn_classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (1): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (2): Linear(in_features=1024, out_features=256, bias=False)\n",
      "    (3): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "    (4): Linear(in_features=256, out_features=10, bias=False)\n",
      "    (5): LIFNode(\n",
      "      v_threshold=1.0, v_reset=0.0, detach_reset=False, step_mode=s, backend=torch, tau=2.0\n",
      "      (surrogate_function): ATan(alpha=2.0, spiking=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyd\\AppData\\Local\\Temp\\ipykernel_14108\\3996333174.py:143: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler() if args.amp else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.0121, Train Acc: 0.9231, Test Loss: 0.0045, Test Acc: 0.9707, Best Test Acc: 0.9707\n",
      "Epoch 1, Train Loss: 0.0039, Train Acc: 0.9764, Test Loss: 0.0031, Test Acc: 0.9804, Best Test Acc: 0.9804\n",
      "Epoch 2, Train Loss: 0.0027, Train Acc: 0.9844, Test Loss: 0.0028, Test Acc: 0.9814, Best Test Acc: 0.9814\n",
      "Epoch 3, Train Loss: 0.0021, Train Acc: 0.9875, Test Loss: 0.0024, Test Acc: 0.9854, Best Test Acc: 0.9854\n",
      "Epoch 4, Train Loss: 0.0017, Train Acc: 0.9903, Test Loss: 0.0025, Test Acc: 0.9838, Best Test Acc: 0.9854\n",
      "Epoch 5, Train Loss: 0.0015, Train Acc: 0.9916, Test Loss: 0.0024, Test Acc: 0.9840, Best Test Acc: 0.9854\n",
      "Epoch 6, Train Loss: 0.0012, Train Acc: 0.9934, Test Loss: 0.0021, Test Acc: 0.9867, Best Test Acc: 0.9867\n",
      "Epoch 7, Train Loss: 0.0012, Train Acc: 0.9930, Test Loss: 0.0024, Test Acc: 0.9848, Best Test Acc: 0.9867\n",
      "Epoch 8, Train Loss: 0.0010, Train Acc: 0.9944, Test Loss: 0.0019, Test Acc: 0.9881, Best Test Acc: 0.9881\n",
      "Epoch 9, Train Loss: 0.0008, Train Acc: 0.9959, Test Loss: 0.0023, Test Acc: 0.9856, Best Test Acc: 0.9881\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import time  \n",
    "import sys  \n",
    "import datetime  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "from torch.cuda import amp  \n",
    "import torchvision  \n",
    "import numpy as np  \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from spikingjelly.activation_based import neuron, encoding, functional, surrogate, layer  \n",
    "\n",
    "class TransformerSNN(nn.Module):  \n",
    "    def __init__(self, img_size=28, patch_size=7, in_channels=1, embed_dim=128, num_heads=4, num_classes=10, tau=2.0):  \n",
    "        super(TransformerSNN, self).__init__()  \n",
    "        \n",
    "        self.patch_embed = nn.Sequential(  \n",
    "            nn.Conv2d(in_channels, embed_dim,   \n",
    "                      kernel_size=patch_size,   \n",
    "                      stride=patch_size),  \n",
    "            layer.BatchNorm2d(embed_dim)  \n",
    "        )  \n",
    "         \n",
    "        num_patches = (img_size // patch_size) ** 2  \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))  \n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(  \n",
    "            nn.TransformerEncoderLayer(  \n",
    "                d_model=embed_dim,   \n",
    "                nhead=num_heads,  \n",
    "                dim_feedforward=embed_dim*4,  \n",
    "                activation=F.relu  \n",
    "            ),  \n",
    "            num_layers=2  \n",
    "        )  \n",
    "        \n",
    "        # SNN 分类器  \n",
    "        self.snn_classifier = nn.Sequential(  \n",
    "            layer.Linear(16 * 128, 1024),\n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),  \n",
    "            layer.Linear(1024, 256, bias=False),  \n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan()),  \n",
    "            layer.Linear(256, num_classes, bias=False),  \n",
    "            neuron.LIFNode(tau=tau, surrogate_function=surrogate.ATan())  \n",
    "        )  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.patch_embed(x)  \n",
    "        B, C, H, W = x.shape  \n",
    "        x = x.view(B, C, H*W).transpose(1, 2)  \n",
    "        x += self.pos_embed  \n",
    "        x = self.transformer_encoder(x)  \n",
    "        x = x.view(B, -1)  \n",
    "        return x \n",
    "    \n",
    "def evaluate_accuracy(data_iter, net, encoder, T):  \n",
    "    acc_sum, n = 0.0, 0\n",
    "    net.eval()  \n",
    "    with torch.no_grad():  \n",
    "        for X, y in data_iter:   \n",
    "            for t in range(T):\n",
    "                spike_input = encoder(X)  # Encode to spikes  \n",
    "                class_output, _ = net(spike_input)  \n",
    "                if t == 0:\n",
    "                    out_fr = torch.zeros_like(class_output) \n",
    "                out_fr += class_output\n",
    "            out_fr = out_fr / T\n",
    "            acc_sum += (out_fr.argmax(1) == y).float().sum().item()  \n",
    "            n += y.numel()\n",
    "            functional.reset_net(net)\n",
    "    return acc_sum / n\n",
    "\n",
    "def main():  \n",
    "    class parser:  \n",
    "        def __init__(self):  \n",
    "            self.T = 10  \n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'  \n",
    "            self.epochs = 10  \n",
    "            self.b = 128  \n",
    "            self.j = 4  \n",
    "            self.data_dir = './mnist_data'  \n",
    "            self.out_dir = './logs'  \n",
    "            self.resume = None\n",
    "            self.amp = True  \n",
    "            self.opt = 'adam'  \n",
    "            self.lr = 1e-3  \n",
    "            self.tau = 2.0  \n",
    "\n",
    "    args = parser()   \n",
    "\n",
    "    net = TransformerSNN(tau=args.tau)  \n",
    "    print(net)  \n",
    "    net.to(args.device)  \n",
    "\n",
    "    # 数据加载 MNIST \n",
    "    train_dataset = torchvision.datasets.MNIST(  \n",
    "        root=args.data_dir,  \n",
    "        train=True,  \n",
    "        transform=torchvision.transforms.ToTensor(),  \n",
    "        download=True  \n",
    "    )  \n",
    "    test_dataset = torchvision.datasets.MNIST(  \n",
    "        root=args.data_dir,  \n",
    "        train=False,  \n",
    "        transform=torchvision.transforms.ToTensor(),  \n",
    "        download=True  \n",
    "    )  \n",
    "\n",
    "    # 数据加载 FashionMNIST\n",
    "    # train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    #         root=args.data_dir,\n",
    "    #         train=True,\n",
    "    #         transform=torchvision.transforms.ToTensor(),\n",
    "    #         download=True)\n",
    "\n",
    "    # test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    #         root=args.data_dir,\n",
    "    #         train=False,\n",
    "    #         transform=torchvision.transforms.ToTensor(),\n",
    "    #         download=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(  \n",
    "        dataset=train_dataset,  \n",
    "        batch_size=args.b,  \n",
    "        shuffle=True,  \n",
    "        drop_last=True,  \n",
    "        num_workers=args.j,  \n",
    "        pin_memory=True  \n",
    "    )  \n",
    "    test_loader = torch.utils.data.DataLoader(  \n",
    "        dataset=test_dataset,  \n",
    "        batch_size=args.b,  \n",
    "        shuffle=False,  \n",
    "        drop_last=False,  \n",
    "        num_workers=args.j,  \n",
    "        pin_memory=True  \n",
    "    )  \n",
    "\n",
    "\n",
    "    # 混合精度和优化器  \n",
    "    scaler = amp.GradScaler() if args.amp else None  \n",
    "    \n",
    "    optimizer = (  \n",
    "        torch.optim.Adam(net.parameters(), lr=args.lr)   \n",
    "        if args.opt == 'adam'   \n",
    "        else torch.optim.SGD(net.parameters(), lr=args.lr, momentum=0.9)  \n",
    "    )  \n",
    "\n",
    "    start_epoch = 0  \n",
    "    if args.resume is not None:  \n",
    "        checkpoint = torch.load(args.resume)  \n",
    "        net.load_state_dict(checkpoint['model_state_dict'])  \n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  \n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    # Poisson 编码器  \n",
    "    encoder = encoding.PoissonEncoder()  \n",
    "\n",
    "    # 训练日志目录  \n",
    "    out_dir = os.path.join(  \n",
    "        args.out_dir,   \n",
    "        f'TransformerSNN_T{args.T}_MNIST'  \n",
    "    )  \n",
    "    os.makedirs(out_dir, exist_ok=True)  \n",
    "\n",
    "    writer = SummaryWriter(log_dir=out_dir)\n",
    "\n",
    "    max_test_acc = -1  \n",
    "\n",
    "    for epoch in range(start_epoch, args.epochs):  \n",
    "        net.train()  \n",
    "        train_loss, train_acc, train_samples = 0, 0, 0  \n",
    "\n",
    "        for img, label in train_loader:  \n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            img = img.to(args.device)  \n",
    "            label = label.to(args.device)  \n",
    "            label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "            out_fr = 0.  \n",
    "            for t in range(args.T):  \n",
    "                # Poisson 编码  \n",
    "                encoded_img = encoder(img)  \n",
    "                # 提取特征  \n",
    "                features = net(encoded_img)  \n",
    "                # 脉冲神经元处理  \n",
    "                out_fr += net.snn_classifier(features)  \n",
    "                \n",
    "            out_fr = out_fr / args.T  \n",
    "            loss = F.mse_loss(out_fr, label_onehot)  \n",
    "\n",
    "            # 反向传播  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "\n",
    "            # 统计指标  \n",
    "            train_samples += label.numel()  \n",
    "            train_loss += loss.item() * label.numel()  \n",
    "            train_acc += (out_fr.argmax(1) == label).float().sum().item()  \n",
    "\n",
    "            # 重置网络状态  \n",
    "            functional.reset_net(net)  \n",
    "\n",
    "        # 验证  \n",
    "        net.eval()  \n",
    "        test_loss, test_acc, test_samples = 0, 0, 0  \n",
    "        with torch.no_grad():  \n",
    "            for img, label in test_loader:  \n",
    "                img = img.to(args.device)  \n",
    "                label = label.to(args.device)\n",
    "                if label.dtype != torch.long:  \n",
    "                    label = label.long()  \n",
    "                label_onehot = F.one_hot(label, 10).float()  \n",
    "\n",
    "                out_fr = 0.  \n",
    "                for t in range(args.T):  \n",
    "                    encoded_img = encoder(img)  \n",
    "                    features = net(encoded_img)  \n",
    "                    out_fr += net.snn_classifier(features)  \n",
    "                \n",
    "                out_fr = out_fr / args.T  \n",
    "                loss = F.mse_loss(out_fr, label_onehot)  \n",
    "\n",
    "                test_samples += label.numel()  \n",
    "                test_loss += loss.item() * label.numel()  \n",
    "                test_acc += (out_fr.argmax(1) == label).float().sum().item()  \n",
    "\n",
    "                functional.reset_net(net)  \n",
    "\n",
    "        # 输出训练信息  \n",
    "        train_loss /= train_samples  \n",
    "        train_acc /= train_samples  \n",
    "        test_loss /= test_samples  \n",
    "        test_acc /= test_samples  \n",
    "\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)  \n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)  \n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch)  \n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch)\n",
    "\n",
    "        # 保存最佳模型  \n",
    "        if test_acc > max_test_acc:  \n",
    "            max_test_acc = test_acc  \n",
    "            torch.save(net.state_dict(), os.path.join(out_dir, 'best_model.pth'))  \n",
    "\n",
    "        print(f'Epoch {epoch}, '  \n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '  \n",
    "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, '  \n",
    "              f'Best Test Acc: {max_test_acc:.4f}')  \n",
    "\n",
    "    # 保存模型  \n",
    "    torch.save(net.state_dict(), os.path.join(out_dir, 'final_model.pth'))  \n",
    "    writer.close()\n",
    "\n",
    "    # tensorboard --logdir=./logs\n",
    "    # MNIST:131m55.6s\n",
    "    # FashionMNIST:121m9.4s\n",
    " \n",
    "if __name__ == '__main__':  \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
